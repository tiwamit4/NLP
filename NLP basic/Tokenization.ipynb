{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695c758e-592b-43d2-be66-3e22462919df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus == paragraph\n",
    "corpus='''Hello welcome, to Amit Ranjan's NLP Notebook.\n",
    "Please do see the entire NLP notebooks to become expert in NLP.\n",
    "This folder contains NLP from Basic to Advance\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ae2236-0ab5-48e5-9dad-c9b41891050f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello welcome, to Amit Ranjan's NLP Notebook.\\nPlease do see the entire NLP notebooks to become expert in NLP.\\nThis folder contains NLP from Basic to Advance\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19756528-bbab-4068-9df7-53f27cb13ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome, to Amit Ranjan's NLP Notebook.\n",
      "Please do see the entire NLP notebooks to become expert in NLP.\n",
      "This folder contains NLP from Basic to Advance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24238eaa-6e9e-4daf-a66f-e9168158e0de",
   "metadata": {},
   "source": [
    "### Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5437986-2d24-4770-a1b8-3d236f084220",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "## sentence --> Paragraph\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2daa71b5-8456-4e10-88bc-6073c43af970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hello welcome, to Amit Ranjan's NLP Notebook.\",\n",
       " 'Please do see the entire NLP notebooks to become expert in NLP.',\n",
       " 'This folder contains NLP from Basic to Advance']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=sent_tokenize(corpus)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0021385-588b-455d-a5f8-403b0b1dd23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dac870e-ba41-48b8-a6d6-0ff1f45f6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome, to Amit Ranjan's NLP Notebook.\n",
      "Please do see the entire NLP notebooks to become expert in NLP.\n",
      "This folder contains NLP from Basic to Advance\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af326f4-aeb7-422e-be8a-bff81136ef8a",
   "metadata": {},
   "source": [
    "### Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11982b8c-4dcb-41d5-bc5e-63d31c51adee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Amit',\n",
       " 'Ranjan',\n",
       " \"'s\",\n",
       " 'NLP',\n",
       " 'Notebook',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'see',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'NLP',\n",
       " 'notebooks',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'This',\n",
       " 'folder',\n",
       " 'contains',\n",
       " 'NLP',\n",
       " 'from',\n",
       " 'Basic',\n",
       " 'to',\n",
       " 'Advance']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "# Paragraph --> words\n",
    "# Sentence --> words  \n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb0748e-e340-4520-baf4-bca53e88125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'welcome', ',', 'to', 'Amit', 'Ranjan', \"'s\", 'NLP', 'Notebook', '.']\n",
      "['Please', 'do', 'see', 'the', 'entire', 'NLP', 'notebooks', 'to', 'become', 'expert', 'in', 'NLP', '.']\n",
      "['This', 'folder', 'contains', 'NLP', 'from', 'Basic', 'to', 'Advance']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a240825-6309-4aa9-aef4-8a663ca91c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Amit',\n",
       " 'Ranjan',\n",
       " \"'\",\n",
       " 's',\n",
       " 'NLP',\n",
       " 'Notebook',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'see',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'NLP',\n",
       " 'notebooks',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'This',\n",
       " 'folder',\n",
       " 'contains',\n",
       " 'NLP',\n",
       " 'from',\n",
       " 'Basic',\n",
       " 'to',\n",
       " 'Advance']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punchuation is also treated as separte word\n",
    "from nltk import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db507d9b-3955-4fde-9303-26a9a85db574",
   "metadata": {},
   "source": [
    "### TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d25206f-8241-4c41-bec4-d9963ce0891d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Amit',\n",
       " 'Ranjan',\n",
       " \"'s\",\n",
       " 'NLP',\n",
       " 'Notebook.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'see',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'NLP',\n",
       " 'notebooks',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP.',\n",
       " 'This',\n",
       " 'folder',\n",
       " 'contains',\n",
       " 'NLP',\n",
       " 'from',\n",
       " 'Basic',\n",
       " 'to',\n",
       " 'Advance']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full stop is also treated as a word but attached with previous word.\n",
    "# But with respect to last word full stop will be attached.\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer=TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266387fb-8491-49b8-beff-ab52bfc4f264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1fd613-0fcb-41ca-9e28-4763388def03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
